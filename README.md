### README.md (Vers√£o Final Atualizada)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

# Desafio Final ‚Äî Pipeline de An√°lise de Sentimento de Resenhas

Este projeto implementa um pipeline de ponta a ponta que baixa resenhas de aplicativos em m√∫ltiplos idiomas, as enriquece usando um LLM local (LM Studio / Ollama) e gera sa√≠das de an√°lise estruturadas. O sistema √© constru√≠do com foco em robustez, testabilidade e boas pr√°ticas de engenharia de software.

---

## üîé Vis√£o Geral

O pipeline executa as seguintes etapas de forma automatizada:

1.  **Download dos Dados:** Baixa o arquivo de resenhas (`.txt`) de uma URL.
2.  **Parsing e Enriquecimento:** L√™ cada linha (`ID$Usu√°rio$Resenha`), aplica limpeza de texto e detecta o idioma original.
3.  **An√°lise com IA:** Envia cada resenha a um LLM local, solicitando uma an√°lise detalhada em formato JSON.
4.  **Valida√ß√£o e Estrutura√ß√£o:** Valida rigorosamente as respostas do LLM usando **Pydantic V2**, garantindo a integridade dos dados e tratando respostas mal formatadas.
5.  **Gera√ß√£o de Sa√≠das:** Salva os dados enriquecidos em `outputs/processed.json` e um resumo executivo em `outputs/summary.txt`.

---

## üèÜ Destaques & Boas Pr√°ticas

*   **Valida√ß√£o Robusta com Pydantic V2:** Utiliza modelos Pydantic com validadores customizados para garantir que todos os dados, desde a entrada at√© a sa√≠da, sejam limpos e consistentes.
*   **Cliente LLM Resiliente:** O `LLMClient` usa a funcionalidade de **retry nativo com backoff exponencial** da biblioteca `openai`, tornando o pipeline resiliente a falhas tempor√°rias de rede ou da API.
*   **Testes Abrangentes (Pytest):** O projeto possui uma su√≠te de testes unit√°rios e de integra√ß√£o que cobre parsing, valida√ß√£o, opera√ß√µes de arquivo e a comunica√ß√£o real com o LLM.
*   **Configura√ß√£o Profissional com `.env`:** Centraliza todas as configura√ß√µes (chaves de API, caminhos, par√¢metros do LLM) em um arquivo `.env`, mantendo o c√≥digo limpo e seguro.
*   **Qualidade de C√≥digo:** O c√≥digo segue as diretrizes da PEP 8 e foi validado com linters para garantir alta legibilidade e manutenibilidade.

---

## ‚úÖ Estrutura do Projeto

```
project_root/
‚îú‚îÄ README.md
‚îú‚îÄ LICENSE
‚îú‚îÄ requirements.txt
‚îú‚îÄ .env.example             # Exemplo de arquivo de configura√ß√£o
‚îú‚îÄ data/
‚îÇ  ‚îî‚îÄ raw/
‚îú‚îÄ outputs/
‚îÇ  ‚îú‚îÄ processed.json
‚îÇ  ‚îî‚îÄ summary.txt
‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ config.py              # Carrega e valida configura√ß√µes com pydantic-settings
‚îÇ  ‚îú‚îÄ logging_config.py      # Configura√ß√£o do logger (fuso BR)
‚îÇ  ‚îú‚îÄ models.py              # Modelos Pydantic V2 (ReviewRaw, ReviewProcessed)
‚îÇ  ‚îú‚îÄ llm_client.py          # Cliente resiliente para a API do LLM
‚îÇ  ‚îú‚îÄ processor.py           # Valida respostas do LLM e analisa resultados
‚îÇ  ‚îú‚îÄ tools/
‚îÇ  ‚îÇ  ‚îú‚îÄ parser.py           # L√™, limpa e enriquece os dados brutos
‚îÇ  ‚îÇ  ‚îú‚îÄ prompt_builder.py   # Constr√≥i prompts din√¢micos e detalhados
‚îÇ  ‚îÇ  ‚îî‚îÄ text_utils.py       # Fun√ß√µes de limpeza de texto e detec√ß√£o de idioma
‚îÇ  ‚îî‚îÄ utils/
‚îÇ     ‚îú‚îÄ file_ops.py         # Fun√ß√µes de alto n√≠vel para salvar arquivos
‚îÇ     ‚îú‚îÄ helpers.py          # Utilit√°rios (ex: safe_json_load aprimorado)
‚îÇ     ‚îî‚îÄ loader.py           # M√≥dulo para download de arquivos
‚îú‚îÄ scripts/
‚îÇ  ‚îî‚îÄ run_pipeline.py        # Orquestrador principal do pipeline
‚îî‚îÄ tests/
   ‚îú‚îÄ test_loader.py
   ‚îú‚îÄ test_parser.py
   ‚îú‚îÄ test_processor.py
   ‚îî‚îÄ test_llm_integration.py
```

---

## üõ† Requisitos

*   Python 3.10+
*   Um servidor de LLM local (LM Studio ou Ollama) rodando com um modelo de chat.

Instale as depend√™ncias com `pip`:
```bash
pip install -r requirements.txt
```

**`requirements.txt`:**
```
# Pydantic e Configura√ß√µes
pydantic>=2.0
pydantic-settings
python-dotenv

# Cliente LLM e HTTP
openai>=1.0
requests

# An√°lise de Texto
langdetect

# Utilit√°rios
pytz

# Testes
pytest
```

---

## ‚öôÔ∏è Configura√ß√£o

### 1. Crie o arquivo `.env`

Na raiz do projeto, crie um arquivo chamado `.env` (voc√™ pode copiar o `.env.example`). Preencha com as informa√ß√µes do seu servidor LLM local:

```ini
# Configura√ß√µes do LLM
LLM_BASE_URL="http://127.0.0.1:1234/v1"
LLM_API_KEY="lm-studio" # ou a chave que seu servidor exigir
LLM_MODEL="google/gemma-2-9b-it" # o modelo que voc√™ carregou no servidor

# Par√¢metros de Resili√™ncia e Gera√ß√£o
LLM_TIMEOUT=60
LLM_MAX_RETRIES=3
LLM_TEMPERATURE=0.0
LLM_MAX_TOKENS=512

# Configura√ß√µes de Logging
LOG_LEVEL="INFO"
```

### 2. Ambiente Virtual (Recomendado)

```bash
python -m venv .venv
source .venv/bin/activate      # macOS / Linux
# .venv\Scripts\activate       # Windows
pip install -r requirements.txt
```

---

## ‚ñ∂Ô∏è Como Rodar o Pipeline Completo

1.  Certifique-se de que seu servidor LLM (LM Studio / Ollama) est√° rodando.
2.  Execute o script principal como um m√≥dulo a partir da **raiz do projeto**:

```bash
python -m scripts.run_pipeline
```
A execu√ß√£o como m√≥dulo (`-m`) √© importante para que as importa√ß√µes de `src` funcionem corretamente.

---

## üìÑ Formato dos Dados de Sa√≠da

### `processed.json`

O arquivo de sa√≠da principal, contendo uma lista de objetos JSON com a an√°lise detalhada de cada resenha:

```json
[
  {
    "user": "Safoan Riyad",
    "original": ")'aimais bien ChatgpT. Mais la derni√©re mise 4 jour a tout gach√©. Elle a tout oubli√©.",
    "translation_pt": "Eu gosto mais do ChatGPT. Mas a √∫ltima atualiza√ß√£o arruinou tudo. Ela esqueceu de tudo.",
    "sentiment": "negative",
    "language": "fr",
    "intensity": "Alta",
    "aspects": [
      "atualiza√ß√£o",
      "funcionalidade",
      "qualidade"
    ],
    "explanation": "A resenha expressa forte insatisfa√ß√£o com a atualiza√ß√£o mais recente, indicando que ela causou perda de funcionalidades e impactou negativamente a experi√™ncia do usu√°rio."
  }
]
```

### `summary.txt`

Um resumo executivo contendo a contagem de sentimentos e o texto original de todas as resenhas concatenadas.

---

## üß† Prompt Utilizado

O pipeline constr√≥i um prompt din√¢mico e detalhado para extrair o m√°ximo de informa√ß√£o do LLM, incluindo a dica de idioma detectado para melhorar a precis√£o:

```
Sua tarefa √© fazer uma an√°lise detalhada da resenha de um aplicativo e retornar um objeto JSON.
O idioma original da resenha foi detectado como 'fr'.

Resenha original: ")'aimais bien ChatgpT. Mais la derni√©re mise 4 jour a tout gach√©. Elle a tout oubli√©."

O JSON de sa√≠da deve ter EXATAMENTE as seguintes chaves:
  - "translation_pt": string (a tradu√ß√£o da resenha para o portugu√™s do Brasil).
  - "sentiment": string (deve ser 'positive', 'negative' ou 'neutral').
  - "intensity": string (a intensidade do sentimento: 'Alta', 'M√©dia' ou 'Baixa').
  - "aspects": uma lista de 1 a 3 palavras-chave em portugu√™s que resumem os pontos principais (ex: ["usabilidade", "bugs", "pre√ßo"]).
  - "explanation": uma frase curta em portugu√™s explicando o porqu√™ da classifica√ß√£o de sentimento.

Responda APENAS com o objeto JSON, sem nenhum texto ou formata√ß√£o adicional.
```

---

## Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT ‚Äî veja o arquivo [LICENSE](LICENSE) para mais detalhes.
